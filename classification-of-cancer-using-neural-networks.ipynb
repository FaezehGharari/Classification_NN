{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3249,"sourceType":"datasetVersion","datasetId":1868}],"dockerImageVersionId":30042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the Modules","metadata":{}},{"cell_type":"markdown","source":"The first 4 lines will make your code reproducible.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(0)\nfrom tensorflow.random import set_seed\nset_seed(0)\n\nimport pandas as pd\nfrom tensorflow import keras\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"markdown","source":"The \"actual\" file contains all 72 patients in the study and the labels.","metadata":{}},{"cell_type":"code","source":"actual_df = pd.read_csv('../input/gene-expression/actual.csv')\nactual_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_df['cancer'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Recode label to numeric.","metadata":{}},{"cell_type":"code","source":"y = actual_df.replace({'ALL':0, 'AML':1})\ny = y.set_index('patient')\nlabels = ['ALL', 'AML']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Loading training and testing datasets.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/gene-expression/data_set_ALL_AML_train.csv')\ntest_df = pd.read_csv('../input/gene-expression/data_set_ALL_AML_independent.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Shape of Training Data: \", train_df.shape)\nprint(\"Shape of Testing Data: \", test_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The 7129 gene descriptions are provided as the rows and the values for each patient as the columns. This will clearly require some tidying up.","metadata":{}},{"cell_type":"markdown","source":"We can remove \"call\" columns from training and testing dataframes.","metadata":{}},{"cell_type":"code","source":"train_to_keep=[col for col in train_df.columns if \"call\" not in col]\ntest_to_keep=[col for col in test_df.columns if \"call\" not in col]\n\nX_train = train_df[train_to_keep]\nX_test = test_df[test_to_keep]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can simply transpose both training and testing dataframes so that genes become columns(features) and patients become rows.","metadata":{}},{"cell_type":"code","source":"X_train = X_train.T\nX_test = X_test.T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The first 2 rows are duplicated so we can remove 'Gene Description' and set 'Gene Accession Number' as the column headers.","metadata":{}},{"cell_type":"code","source":"X_train.columns = X_train.iloc[1]\nX_test.columns = X_test.iloc[1]\n\nX_train = X_train.drop(['Gene Description', 'Gene Accession Number'])\nX_test = X_test.drop(['Gene Description', 'Gene Accession Number'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Neither the training and testing row indexes are not in numeric order, so it's important that we reorder these, so that the labels will line up with the corresponding data.","metadata":{}},{"cell_type":"code","source":"X_train.index = X_train.index.astype(int)\nX_train.sort_index(inplace=True)\n\nX_test.index = X_test.index.astype(int)\nX_test.sort_index(inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the end, our data looks like this:","metadata":{}},{"cell_type":"code","source":"print(\"Shape of Training data:\\t\", X_train.shape)\nprint(\"Shape of Testing Data:\\t\", X_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's split the target labels into training and testing targets.","metadata":{}},{"cell_type":"code","source":"y_train = y['cancer'][:38]\ny_test = y['cancer'][38:]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Standardizing Features","metadata":{}},{"cell_type":"markdown","source":"Note that the test set must use identical scaling to the training set.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols=2, figsize=(15,5))\nsns.distplot(np.concatenate(X_train.values), ax=ax[0]).set_title('Original Data')\nsns.distplot(np.concatenate(X_train_scaled), ax=ax[1]).set_title('Scaled Data')\nplt.tight_layout\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dimentionality reduction(PCA)","metadata":{}},{"cell_type":"markdown","source":"You need to apply the same PCA on training and testing sets.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components = 0.95)\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\nprint(X_train_pca.shape)\nprint(X_test_pca.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"95% of variance is explained by 32 principal components. We can't plot something in 32 dimensions, so let's just see what the PCA looks like when we just pick the top three compoments.","metadata":{}},{"cell_type":"code","source":"pca3 = PCA(n_components = 3).fit_transform(X_train_scaled)\ncolors = np.where(y_train==0, 'red', 'blue')\nplt.clf()\nfig = plt.figure(1, figsize=(10,6 ))\nax = Axes3D(fig, elev=-150, azim=110,)\nax.scatter(pca3[:, 0], pca3[:, 1], pca3[:, 2], c=colors, cmap=plt.cm.Paired,linewidths=10)\nax.set_title(\"First three PCA directions\")\nax.set_xlabel(\"PC1\")\nax.w_xaxis.set_ticklabels([])\nax.set_ylabel(\"PC2\")\nax.w_yaxis.set_ticklabels([])\nax.set_zlabel(\"PC3\")\nax.w_zaxis.set_ticklabels([])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"code","source":"NN_model = keras.Sequential([\n    layers.Dense(32, activation='relu', input_shape=X_train_pca[1].shape),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NN_model.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['binary_accuracy']\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.005,\n    restore_best_weights=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_history = NN_model.fit(\n    X_train_pca, y_train,\n    validation_data=(X_test_pca, y_test),\n    batch_size = 8,\n    epochs = 200,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = NN_model.predict_classes(X_test_pca)\nprint('Neural Network accuracy: ', round(accuracy_score(y_test, pred), 3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm_nn = confusion_matrix(y_test, pred)\n\nax = plt.subplot()\nsns.heatmap(cm_nn, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n# Labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels') \nax.set_title('Neural Network Confusion Matrix') \nax.xaxis.set_ticklabels(labels) \nax.yaxis.set_ticklabels(labels, rotation=360);","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}